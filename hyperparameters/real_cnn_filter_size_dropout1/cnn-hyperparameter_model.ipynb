{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 14:00:28.120270: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 14:00:35.174190: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/home/stenmarken/miniconda3/envs/tensorflow/lib/\n",
      "2023-05-03 14:00:35.174291: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/home/stenmarken/miniconda3/envs/tensorflow/lib/\n",
      "2023-05-03 14:00:35.174299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/stenmarken/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import time\n",
    "import collections\n",
    "import keras\n",
    "import random\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import MaxPooling1D, Conv1D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, LSTM, ELU, Bidirectional, Attention\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, CuDNNLSTM\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras_tuner\n",
    "from keras import backend as K\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model_type = 'tune_cnn'\n",
    "global_folder_name = 'weyo4'\n",
    "file_suffix = 'weyo1'\n",
    "global_batch_size = 32\n",
    "global_epochs = 50\n",
    "global_learning_rate = 0.0001\n",
    "own_file_path = os.getcwd() \n",
    "global_hyperparameter_folder_name = 'real_cnn_filter_size_dropout1' #lstm_filter_size_dropout1' #'cnn_filter_size_dropout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instrument_code(filename):\n",
    "    \"\"\"\n",
    "    Function that takes in a filename and returns instrument based on naming convention\n",
    "    \"\"\"\n",
    "    # Synth lead borttagen. id = 9\n",
    "    class_names=['bass', 'brass', 'flute', 'guitar', \n",
    "             'keyboard', 'mallet', 'organ', 'reed', \n",
    "             'string', 'vocal']\n",
    "    \n",
    "    for name in class_names:\n",
    "        if name in filename:\n",
    "            return class_names.index(name)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        X_train_full  = pickle.load(f)\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for (key, value) in X_train_full:\n",
    "        X_train.append(value)\n",
    "        y_train.append(instrument_code(key))\n",
    "\n",
    "    X_train_numpy = np.array(X_train)\n",
    "    y_train_numpy = np.array(y_train)\n",
    "    return (X_train_numpy, y_train_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_test_data(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        old_X_test_full = pickle.load(f)\n",
    "\n",
    "    old_X_test = []\n",
    "    old_y_test = []\n",
    "\n",
    "    for(key, value) in old_X_test_full.items():\n",
    "        #temporal_value = np.mean(value, axis = 1)\n",
    "        old_X_test.append(value)\n",
    "        old_y_test.append(instrument_code(key))\n",
    "        \n",
    "    old_y_test_numpy = np.asarray(old_y_test)\n",
    "    old_X_test_numpy = np.asarray(old_X_test)\n",
    "    return (old_X_test_numpy, old_y_test_numpy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred):\n",
    "    print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_cnn_model(hp):\n",
    "    \"\"\"\n",
    "    Function that builds a CNN model with optimized hyperparameters including filter size and dropout rate\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), \n",
    "                    activation='relu', padding='same', input_shape=(126, 13, 1)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), \n",
    "                    activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Conv2D(filters = hp.Choice('conv_2_filters_1', values = [32, 64, 128]), kernel_size=(3, 3),\n",
    "                    activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters = hp.Choice('conv_2_filters_1', values = [32, 64, 128]), kernel_size=(3, 3),\n",
    "                    activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Conv2D(filters = hp.Choice('conv_2_filters_2', values = [32, 64, 128, 256]), kernel_size=(3, 3),\n",
    "                    activation='relu', padding='same'))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=global_learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_lstm_model(hp):\n",
    "    \"\"\"\n",
    "    Function that builds a LSTM model with optimized hyperparameters including filter size and dropout rate\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    #model.add(Bidirectional(CuDNNLSTM(128, return_sequences=True), input_shape=(126, 128)))\n",
    "    #model.add(CuDNNLSTM(4, input_shape=(126, 128), return_sequences=True))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, input_shape=(126, 13), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout_lstm', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units = hp.Choice('lstm_layer_units_1', values = [32, 64, 128]), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout_lstm', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units = hp.Choice('lstm_layer_units_1', values = [32, 64, 128]), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout_lstm', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units = hp.Choice('lstm_layer_units_2', values = [32, 64, 128]), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout_lstm', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units = hp.Choice('lstm_layer_units_2', values = [32, 64, 128]), return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout_lstm', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    #model.add(LSTM(16, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=global_learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model():    \n",
    "    input_shape = (126, 13, 1)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128,(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model():\n",
    "    model = Sequential()\n",
    "    #model.add(Bidirectional(CuDNNLSTM(128, return_sequences=True), input_shape=(126, 128)))\n",
    "    #model.add(CuDNNLSTM(4, input_shape=(126, 128), return_sequences=True))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, input_shape=(126, 13), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, return_sequences=True))\n",
    "    #model.add(LSTM(16, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(history, acc_file_path, loss_file_path):\n",
    "    # Taget från https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig(acc_file_path)\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig(loss_file_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def plt_confusion_matrix(model, X_test, y_test, confusion_matrix_file_path):    \n",
    "    y_prediction = model.predict(X_test)\n",
    "    y_prediction = np.argmax(y_prediction, axis = 1)\n",
    "    result = confusion_matrix(y_test, y_prediction , normalize='pred')\n",
    "\n",
    "    df_cm = pd.DataFrame(result, index = [i for i in [\"bass\", \"brass\", \"flute\", \"guitar\", \"keyboard\", \"mallet\", \"organ\", \"reed\", \"string\", \"vocal\"]],\n",
    "                    columns = [i for i in [\"bass\", \"brass\", \"flute\", \"guitar\", \"keyboard\", \"mallet\", \"organ\", \"reed\", \"string\", \"vocal\"]])\n",
    "\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.savefig(confusion_matrix_file_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn(fold_index):\n",
    "\n",
    "    old_test_file = 'CustomDataFull/testdata2000.pkl'\n",
    "\n",
    "    train_file = 'folds/' + str(fold_index) + 'train_' + file_suffix\n",
    "    test_file = 'folds/' + str(fold_index) + 'test_' + file_suffix\n",
    "    valid_file = 'folds/' + str(fold_index) + 'valid_' + file_suffix\n",
    "\n",
    "    X_train, y_train = get_data_from_file(train_file)\n",
    "    X_test, y_test = get_data_from_file(test_file)\n",
    "    X_valid, y_valid = get_data_from_file(valid_file)\n",
    "    old_X_test, old_y_test = get_old_test_data(old_test_file)\n",
    "\n",
    "    fold_path = 'results/cnn_results/' + global_folder_name + '/' + str(fold_index) + file_suffix + '/'\n",
    "    if not os.path.exists(fold_path):\n",
    "        os.makedirs(fold_path)\n",
    "\n",
    "    model = build_cnn_model()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=global_learning_rate), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    history = model.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid), batch_size=global_batch_size, epochs=global_epochs, shuffle=True, verbose=2)\n",
    "    model.save(fold_path + str(fold_index) + 'model_' + file_suffix + '.h5')\n",
    "\n",
    "    history_name = fold_path + str(fold_index) + 'history_' + file_suffix + '.history'\n",
    "\n",
    "    with open(history_name, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_prediction = model.predict(X_test)\n",
    "    y_prediction = np.argmax(y_prediction, axis = 1)\n",
    "\n",
    "    print(\"\\n\\ny_test : \", y_test)\n",
    "    print(\"\\n\\ny_prediction : \", y_prediction)\n",
    "\n",
    "    f1_scores = metrics.classification_report(y_test, y_prediction, digits=3)\n",
    "\n",
    "    original_scores = model.evaluate(old_X_test, old_y_test, verbose=1)\n",
    "    original_y_prediction = model.predict(old_X_test)\n",
    "    original_y_prediction = np.argmax(original_y_prediction, axis = 1)\n",
    "    original_f1_scores = metrics.classification_report(old_y_test, original_y_prediction, digits=3)\n",
    "\n",
    "    score_file = fold_path + str(fold_index) + 'score_' + file_suffix + '.txt'\n",
    "    with open(score_file, 'w') as f:\n",
    "        f.write('fold: ' + str(fold_index) + '\\n')\n",
    "        f.write('scores: ' + str(scores) + '\\n')\n",
    "        f.write('scores with original testdata: ' + str(original_scores) + '\\n')\n",
    "        f.write('f1_scores:\\n' + str(f1_scores) + '\\n')\n",
    "        f.write('f1_scores with original testdata:\\n' + str(original_f1_scores) + '\\n')\n",
    "\n",
    "    loss_file_path = fold_path + str(fold_index) + 'loss_' + file_suffix + '.png'\n",
    "    acc_file_path = fold_path + str(fold_index) + 'acc_' + file_suffix + '.png'\n",
    "    plot_acc_loss(history.history, acc_file_path, loss_file_path)\n",
    "\n",
    "    confusion_matrix_file_path = fold_path + str(fold_index) + 'confusion_matrix_' + file_suffix + '.png'\n",
    "    plt_confusion_matrix(model, X_test, y_test, confusion_matrix_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm(fold_index):\n",
    "    old_test_file = 'CustomDataFull/testdata2000.pkl'\n",
    "    train_file = 'folds/' + str(fold_index) + 'train_' + file_suffix\n",
    "    test_file = 'folds/' + str(fold_index) + 'test_' + file_suffix\n",
    "    valid_file = 'folds/' + str(fold_index) + 'valid_' + file_suffix\n",
    "\n",
    "    X_train, y_train = get_data_from_file(train_file)\n",
    "    X_test, y_test = get_data_from_file(test_file)\n",
    "    X_valid, y_valid = get_data_from_file(valid_file)\n",
    "    old_X_test, old_y_test = get_old_test_data(old_test_file)\n",
    "\n",
    "    fold_path = 'results/lstm_results/' + global_folder_name + '/' + str(fold_index) + file_suffix + '/'\n",
    "    if not os.path.exists(fold_path):\n",
    "        os.makedirs(fold_path)\n",
    "\n",
    "    model = build_lstm_model()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=global_learning_rate), metrics=['accuracy'])\n",
    "    #model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=global_learning_rate), metrics=['accuracy', \n",
    "    #              tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tfa.metrics.F1Score(num_classes=10, average='macro',\n",
    "    #              threshold=0.5)])\n",
    "    \n",
    "    model.summary()\n",
    "    history = model.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid), batch_size=global_batch_size, epochs=global_epochs, shuffle=True, verbose=2)\n",
    "    model.save(fold_path + str(fold_index) + 'model_' + file_suffix + '.h5')\n",
    "\n",
    "    history_name = fold_path + str(fold_index) + 'history_' + file_suffix + '.history'\n",
    "\n",
    "    with open(history_name, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "    y_prediction = model.predict(X_test)\n",
    "    y_prediction = np.argmax(y_prediction, axis = 1)\n",
    "    f1_scores = metrics.classification_report(y_test, y_prediction, digits=3)\n",
    "\n",
    "    original_scores = model.evaluate(old_X_test, old_y_test, verbose=1)\n",
    "    original_y_prediction = model.predict(old_X_test)\n",
    "    original_y_prediction = np.argmax(original_y_prediction, axis = 1)\n",
    "    original_f1_scores = metrics.classification_report(old_y_test, original_y_prediction, digits=3)\n",
    "    \n",
    "    score_file = fold_path + str(fold_index) + 'score_' + file_suffix + '.txt'\n",
    "    with open(score_file, 'w') as f:\n",
    "        f.write('fold: ' + str(fold_index) + '\\n')\n",
    "        f.write('scores: ' + str(scores) + '\\n')\n",
    "        f.write('scores with original testdata: ' + str(original_scores) + '\\n')\n",
    "        f.write('f1_scores: ' + str(f1_scores) + '\\n')\n",
    "        f.write('f1_scores with original testdata: ' + str(original_f1_scores) + '\\n')\n",
    "\n",
    "    loss_file_path = fold_path + str(fold_index) + 'loss_' + file_suffix + '.png'\n",
    "    acc_file_path = fold_path + str(fold_index) + 'acc_' + file_suffix + '.png'\n",
    "    plot_acc_loss(history.history, acc_file_path, loss_file_path)\n",
    "\n",
    "    confusion_matrix_file_path = fold_path + str(fold_index) + 'confusion_matrix_' + file_suffix + '.png'\n",
    "    plt_confusion_matrix(model, X_test, y_test, confusion_matrix_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_cnn():\n",
    "    \"\"\"\n",
    "    OBS! Efter en körning så printas summaryn över resultaten gällande de olika hyperparametrarna. Spara dom!\n",
    "    \"\"\"\n",
    "    tuner = keras_tuner.RandomSearch(hyperparameter_cnn_model, overwrite=True, objective='val_accuracy', max_trials=3, executions_per_trial=3, directory='hyperparameters', project_name=global_hyperparameter_folder_name)\n",
    "    tuner.search_space_summary()\n",
    "    fold_index = 0 # Godtyckligt val!!!\n",
    "\n",
    "    train_file = 'folds/' + str(fold_index) + 'train_' + file_suffix\n",
    "    test_file = 'folds/' + str(fold_index) + 'test_' + file_suffix\n",
    "    valid_file = 'folds/' + str(fold_index) + 'valid_' + file_suffix\n",
    "\n",
    "    X_train, y_train = get_data_from_file(train_file)\n",
    "    X_test, y_test = get_data_from_file(test_file)\n",
    "    X_valid, y_valid = get_data_from_file(valid_file)\n",
    "    tuner.search(X_train, y_train, epochs=global_epochs, batch_size=global_batch_size, validation_data=(X_valid, y_valid), shuffle=True, verbose=2, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='hyperparameters/' + global_hyperparameter_folder_name)])\n",
    "    \n",
    "    print(tuner.get_best_hyperparameters()[0].values)\n",
    "\n",
    "    hyperparameter_log_name = 'hyperparameters/' + global_hyperparameter_folder_name + '/log.txt'\n",
    "\n",
    "    with open(hyperparameter_log_name, 'w') as f:\n",
    "        f.write('best hyperparameters: ' + str(tuner.get_best_hyperparameters()[0].values) + '\\n')\n",
    "        f.write(str(tuner.results_summary()) + '\\n')\n",
    "\n",
    "    tuner.results_summary()\n",
    "\n",
    "    copy_file = 'hyperparameters/' + global_hyperparameter_folder_name + '/' + 'cnn-hyperparameter_model.ipynb'\n",
    "    own_file_name = own_file_path + '/k-fold_cross_validation.ipynb'\n",
    "    shutil.copyfile(own_file_name, copy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lstm():\n",
    "    \"\"\"\n",
    "    OBS! Efter en körning så printas summaryn över resultaten gällande de olika hyperparametrarna. Spara dom!\n",
    "    \"\"\"\n",
    "    tuner = keras_tuner.RandomSearch(hyperparameter_lstm_model, overwrite=True, objective='val_accuracy', max_trials=3, executions_per_trial=3, directory='hyperparameters', project_name=global_hyperparameter_folder_name)\n",
    "    tuner.search_space_summary()\n",
    "    fold_index = 0 # Godtyckligt val!!!\n",
    "\n",
    "    train_file = 'folds/' + str(fold_index) + 'train_' + file_suffix\n",
    "    test_file = 'folds/' + str(fold_index) + 'test_' + file_suffix\n",
    "    valid_file = 'folds/' + str(fold_index) + 'valid_' + file_suffix\n",
    "\n",
    "    X_train, y_train = get_data_from_file(train_file)\n",
    "    X_test, y_test = get_data_from_file(test_file)\n",
    "    X_valid, y_valid = get_data_from_file(valid_file)\n",
    "    tuner.search(X_train, y_train, epochs=global_epochs, batch_size=global_batch_size, validation_data=(X_valid, y_valid), shuffle=True, verbose=2, callbacks=[tf.keras.callbacks.TensorBoard(log_dir='hyperparameters/' + global_hyperparameter_folder_name)])\n",
    "    \n",
    "    print(tuner.get_best_hyperparameters()[0].values)\n",
    "\n",
    "    hyperparameter_log_name = 'hyperparameters/' + global_hyperparameter_folder_name + '/log.txt'\n",
    "\n",
    "    with open(hyperparameter_log_name, 'w') as f:\n",
    "        f.write('best hyperparameters: ' + str(tuner.get_best_hyperparameters()[0].values) + '\\n')\n",
    "    \n",
    "    tuner.results_summary()\n",
    "    \n",
    "    copy_file = 'hyperparameters/' + global_hyperparameter_folder_name + '/' + 'lstm-hyperparameter_model.ipynb'\n",
    "    own_file_name = own_file_path + '/k-fold_cross_validation.ipynb'\n",
    "    shutil.copyfile(own_file_name, copy_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn_5_fold_cross_validation():\n",
    "    path = 'results/cnn_results/' + global_folder_name\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    copy_file = 'results/cnn_results/' + global_folder_name + '/' + 'copied_model.ipynb'\n",
    "    own_file_name = own_file_path + '/k-fold_cross_validation.ipynb'\n",
    "    shutil.copyfile(own_file_name, copy_file)\n",
    "\n",
    "    for i in range(0, 5):\n",
    "        run_cnn(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_5_fold_cross_validation():\n",
    "    path = 'results/lstm_results/' + global_folder_name\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    copy_file = 'results/lstm_results/' + global_folder_name + '/' + 'copied_model.ipynb'\n",
    "    own_file_name = own_file_path + '/k-fold_cross_validation.ipynb'\n",
    "    shutil.copyfile(own_file_name, copy_file)\n",
    "\n",
    "    for i in range(0, 5):\n",
    "        run_lstm(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 49m 59s]\n",
      "val_accuracy: 0.9689904650052389\n",
      "\n",
      "Best val_accuracy So Far: 0.9787428577740988\n",
      "Total elapsed time: 01h 43m 23s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.5               |0.1               |dropout_1\n",
      "128               |128               |conv_2_filters_1\n",
      "64                |128               |conv_2_filters_2\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 15:44:40.645437: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0064s vs `on_train_batch_end` time: 0.0097s). Check your callbacks.\n",
      "2188/2188 - 22s - loss: 2.0398 - accuracy: 0.2299 - val_loss: 1.6074 - val_accuracy: 0.4214 - 22s/epoch - 10ms/step\n",
      "Epoch 2/50\n",
      "2188/2188 - 20s - loss: 1.4742 - accuracy: 0.4641 - val_loss: 1.2528 - val_accuracy: 0.5280 - 20s/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "2188/2188 - 20s - loss: 1.2110 - accuracy: 0.5571 - val_loss: 0.9988 - val_accuracy: 0.6333 - 20s/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "2188/2188 - 20s - loss: 1.0684 - accuracy: 0.6077 - val_loss: 0.8970 - val_accuracy: 0.6731 - 20s/epoch - 9ms/step\n",
      "Epoch 5/50\n",
      "2188/2188 - 20s - loss: 0.9747 - accuracy: 0.6426 - val_loss: 0.7896 - val_accuracy: 0.7147 - 20s/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "2188/2188 - 20s - loss: 0.9017 - accuracy: 0.6698 - val_loss: 0.7965 - val_accuracy: 0.7110 - 20s/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "2188/2188 - 20s - loss: 0.8400 - accuracy: 0.6931 - val_loss: 0.6581 - val_accuracy: 0.7665 - 20s/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "2188/2188 - 20s - loss: 0.7838 - accuracy: 0.7124 - val_loss: 0.6123 - val_accuracy: 0.7798 - 20s/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "2188/2188 - 20s - loss: 0.7317 - accuracy: 0.7337 - val_loss: 0.5608 - val_accuracy: 0.8031 - 20s/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "2188/2188 - 20s - loss: 0.6986 - accuracy: 0.7460 - val_loss: 0.5763 - val_accuracy: 0.7944 - 20s/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "2188/2188 - 20s - loss: 0.6591 - accuracy: 0.7603 - val_loss: 0.4978 - val_accuracy: 0.8183 - 20s/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "2188/2188 - 20s - loss: 0.6355 - accuracy: 0.7678 - val_loss: 0.4683 - val_accuracy: 0.8322 - 20s/epoch - 9ms/step\n",
      "Epoch 13/50\n",
      "2188/2188 - 20s - loss: 0.5974 - accuracy: 0.7820 - val_loss: 0.4298 - val_accuracy: 0.8435 - 20s/epoch - 9ms/step\n",
      "Epoch 14/50\n",
      "2188/2188 - 20s - loss: 0.5791 - accuracy: 0.7887 - val_loss: 0.4382 - val_accuracy: 0.8454 - 20s/epoch - 9ms/step\n",
      "Epoch 15/50\n",
      "2188/2188 - 19s - loss: 0.5542 - accuracy: 0.7986 - val_loss: 0.3860 - val_accuracy: 0.8626 - 19s/epoch - 9ms/step\n",
      "Epoch 16/50\n",
      "2188/2188 - 19s - loss: 0.5342 - accuracy: 0.8056 - val_loss: 0.3861 - val_accuracy: 0.8654 - 19s/epoch - 9ms/step\n",
      "Epoch 17/50\n",
      "2188/2188 - 19s - loss: 0.5176 - accuracy: 0.8115 - val_loss: 0.3478 - val_accuracy: 0.8737 - 19s/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "2188/2188 - 19s - loss: 0.4950 - accuracy: 0.8197 - val_loss: 0.3372 - val_accuracy: 0.8803 - 19s/epoch - 9ms/step\n",
      "Epoch 19/50\n",
      "2188/2188 - 20s - loss: 0.4801 - accuracy: 0.8232 - val_loss: 0.3212 - val_accuracy: 0.8846 - 20s/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "2188/2188 - 20s - loss: 0.4615 - accuracy: 0.8316 - val_loss: 0.3090 - val_accuracy: 0.8875 - 20s/epoch - 9ms/step\n",
      "Epoch 21/50\n",
      "2188/2188 - 20s - loss: 0.4502 - accuracy: 0.8365 - val_loss: 0.2981 - val_accuracy: 0.8941 - 20s/epoch - 9ms/step\n",
      "Epoch 22/50\n",
      "2188/2188 - 20s - loss: 0.4363 - accuracy: 0.8405 - val_loss: 0.2842 - val_accuracy: 0.8962 - 20s/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "2188/2188 - 20s - loss: 0.4267 - accuracy: 0.8442 - val_loss: 0.2746 - val_accuracy: 0.9024 - 20s/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "2188/2188 - 19s - loss: 0.4156 - accuracy: 0.8485 - val_loss: 0.2663 - val_accuracy: 0.9063 - 19s/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "2188/2188 - 19s - loss: 0.4022 - accuracy: 0.8526 - val_loss: 0.2646 - val_accuracy: 0.9065 - 19s/epoch - 9ms/step\n",
      "Epoch 26/50\n",
      "2188/2188 - 19s - loss: 0.3911 - accuracy: 0.8578 - val_loss: 0.2675 - val_accuracy: 0.9046 - 19s/epoch - 9ms/step\n",
      "Epoch 27/50\n",
      "2188/2188 - 19s - loss: 0.3793 - accuracy: 0.8616 - val_loss: 0.2458 - val_accuracy: 0.9144 - 19s/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "2188/2188 - 19s - loss: 0.3742 - accuracy: 0.8631 - val_loss: 0.2479 - val_accuracy: 0.9127 - 19s/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "2188/2188 - 19s - loss: 0.3629 - accuracy: 0.8670 - val_loss: 0.2281 - val_accuracy: 0.9197 - 19s/epoch - 9ms/step\n",
      "Epoch 30/50\n",
      "2188/2188 - 19s - loss: 0.3561 - accuracy: 0.8697 - val_loss: 0.2238 - val_accuracy: 0.9242 - 19s/epoch - 9ms/step\n",
      "Epoch 31/50\n",
      "2188/2188 - 19s - loss: 0.3487 - accuracy: 0.8717 - val_loss: 0.2233 - val_accuracy: 0.9238 - 19s/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "2188/2188 - 19s - loss: 0.3396 - accuracy: 0.8770 - val_loss: 0.2068 - val_accuracy: 0.9304 - 19s/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "2188/2188 - 19s - loss: 0.3333 - accuracy: 0.8779 - val_loss: 0.2230 - val_accuracy: 0.9227 - 19s/epoch - 9ms/step\n",
      "Epoch 34/50\n",
      "2188/2188 - 19s - loss: 0.3261 - accuracy: 0.8815 - val_loss: 0.2096 - val_accuracy: 0.9266 - 19s/epoch - 9ms/step\n",
      "Epoch 35/50\n",
      "2188/2188 - 19s - loss: 0.3225 - accuracy: 0.8822 - val_loss: 0.1919 - val_accuracy: 0.9335 - 19s/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "2188/2188 - 19s - loss: 0.3147 - accuracy: 0.8863 - val_loss: 0.1948 - val_accuracy: 0.9338 - 19s/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "2188/2188 - 19s - loss: 0.3072 - accuracy: 0.8878 - val_loss: 0.1869 - val_accuracy: 0.9349 - 19s/epoch - 9ms/step\n",
      "Epoch 38/50\n",
      "2188/2188 - 19s - loss: 0.3052 - accuracy: 0.8885 - val_loss: 0.1824 - val_accuracy: 0.9386 - 19s/epoch - 9ms/step\n",
      "Epoch 39/50\n",
      "2188/2188 - 19s - loss: 0.2958 - accuracy: 0.8912 - val_loss: 0.1803 - val_accuracy: 0.9389 - 19s/epoch - 9ms/step\n",
      "Epoch 40/50\n",
      "2188/2188 - 19s - loss: 0.2958 - accuracy: 0.8919 - val_loss: 0.1832 - val_accuracy: 0.9387 - 19s/epoch - 9ms/step\n",
      "Epoch 41/50\n",
      "2188/2188 - 19s - loss: 0.2850 - accuracy: 0.8945 - val_loss: 0.1691 - val_accuracy: 0.9435 - 19s/epoch - 9ms/step\n",
      "Epoch 42/50\n",
      "2188/2188 - 19s - loss: 0.2824 - accuracy: 0.8966 - val_loss: 0.1732 - val_accuracy: 0.9423 - 19s/epoch - 9ms/step\n",
      "Epoch 43/50\n",
      "2188/2188 - 19s - loss: 0.2794 - accuracy: 0.8991 - val_loss: 0.1700 - val_accuracy: 0.9435 - 19s/epoch - 9ms/step\n",
      "Epoch 44/50\n",
      "2188/2188 - 19s - loss: 0.2727 - accuracy: 0.8995 - val_loss: 0.1805 - val_accuracy: 0.9371 - 19s/epoch - 9ms/step\n",
      "Epoch 45/50\n",
      "2188/2188 - 19s - loss: 0.2686 - accuracy: 0.9014 - val_loss: 0.1782 - val_accuracy: 0.9413 - 19s/epoch - 9ms/step\n",
      "Epoch 46/50\n",
      "2188/2188 - 19s - loss: 0.2614 - accuracy: 0.9051 - val_loss: 0.1576 - val_accuracy: 0.9491 - 19s/epoch - 9ms/step\n",
      "Epoch 47/50\n",
      "2188/2188 - 19s - loss: 0.2615 - accuracy: 0.9040 - val_loss: 0.1654 - val_accuracy: 0.9437 - 19s/epoch - 9ms/step\n",
      "Epoch 48/50\n",
      "2188/2188 - 19s - loss: 0.2569 - accuracy: 0.9059 - val_loss: 0.1714 - val_accuracy: 0.9422 - 19s/epoch - 9ms/step\n",
      "Epoch 49/50\n",
      "2188/2188 - 19s - loss: 0.2493 - accuracy: 0.9097 - val_loss: 0.1684 - val_accuracy: 0.9422 - 19s/epoch - 9ms/step\n",
      "Epoch 50/50\n",
      "2188/2188 - 19s - loss: 0.2544 - accuracy: 0.9078 - val_loss: 0.1611 - val_accuracy: 0.9475 - 19s/epoch - 9ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 16:00:53.424406: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0095s). Check your callbacks.\n",
      "2188/2188 - 21s - loss: 2.0374 - accuracy: 0.2271 - val_loss: 1.6300 - val_accuracy: 0.3990 - 21s/epoch - 9ms/step\n",
      "Epoch 2/50\n",
      "2188/2188 - 19s - loss: 1.5176 - accuracy: 0.4472 - val_loss: 1.2450 - val_accuracy: 0.5489 - 19s/epoch - 9ms/step\n",
      "Epoch 3/50\n",
      "2188/2188 - 19s - loss: 1.2433 - accuracy: 0.5437 - val_loss: 1.0353 - val_accuracy: 0.6253 - 19s/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "2188/2188 - 19s - loss: 1.1129 - accuracy: 0.5912 - val_loss: 0.9543 - val_accuracy: 0.6554 - 19s/epoch - 9ms/step\n",
      "Epoch 5/50\n",
      "2188/2188 - 19s - loss: 1.0199 - accuracy: 0.6235 - val_loss: 0.8398 - val_accuracy: 0.6970 - 19s/epoch - 9ms/step\n",
      "Epoch 6/50\n",
      "2188/2188 - 19s - loss: 0.9509 - accuracy: 0.6491 - val_loss: 0.7640 - val_accuracy: 0.7200 - 19s/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "2188/2188 - 19s - loss: 0.8865 - accuracy: 0.6754 - val_loss: 0.7296 - val_accuracy: 0.7373 - 19s/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "2188/2188 - 19s - loss: 0.8338 - accuracy: 0.6953 - val_loss: 0.6685 - val_accuracy: 0.7611 - 19s/epoch - 9ms/step\n",
      "Epoch 9/50\n",
      "2188/2188 - 19s - loss: 0.7896 - accuracy: 0.7110 - val_loss: 0.6024 - val_accuracy: 0.7825 - 19s/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "2188/2188 - 19s - loss: 0.7466 - accuracy: 0.7283 - val_loss: 0.5770 - val_accuracy: 0.7952 - 19s/epoch - 9ms/step\n",
      "Epoch 11/50\n",
      "2188/2188 - 19s - loss: 0.7148 - accuracy: 0.7399 - val_loss: 0.5557 - val_accuracy: 0.7990 - 19s/epoch - 9ms/step\n",
      "Epoch 12/50\n",
      "2188/2188 - 19s - loss: 0.6841 - accuracy: 0.7484 - val_loss: 0.5087 - val_accuracy: 0.8150 - 19s/epoch - 9ms/step\n",
      "Epoch 13/50\n",
      "2188/2188 - 19s - loss: 0.6521 - accuracy: 0.7614 - val_loss: 0.4940 - val_accuracy: 0.8235 - 19s/epoch - 9ms/step\n",
      "Epoch 14/50\n",
      "2188/2188 - 19s - loss: 0.6301 - accuracy: 0.7685 - val_loss: 0.4618 - val_accuracy: 0.8385 - 19s/epoch - 9ms/step\n",
      "Epoch 15/50\n",
      "2188/2188 - 19s - loss: 0.6058 - accuracy: 0.7784 - val_loss: 0.4350 - val_accuracy: 0.8429 - 19s/epoch - 9ms/step\n",
      "Epoch 16/50\n",
      "2188/2188 - 19s - loss: 0.5857 - accuracy: 0.7847 - val_loss: 0.4263 - val_accuracy: 0.8467 - 19s/epoch - 9ms/step\n",
      "Epoch 17/50\n",
      "2188/2188 - 19s - loss: 0.5630 - accuracy: 0.7939 - val_loss: 0.4227 - val_accuracy: 0.8451 - 19s/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "2188/2188 - 19s - loss: 0.5461 - accuracy: 0.7984 - val_loss: 0.4039 - val_accuracy: 0.8501 - 19s/epoch - 9ms/step\n",
      "Epoch 19/50\n",
      "2188/2188 - 19s - loss: 0.5320 - accuracy: 0.8036 - val_loss: 0.3761 - val_accuracy: 0.8680 - 19s/epoch - 9ms/step\n",
      "Epoch 20/50\n",
      "2188/2188 - 19s - loss: 0.5103 - accuracy: 0.8143 - val_loss: 0.3490 - val_accuracy: 0.8699 - 19s/epoch - 9ms/step\n",
      "Epoch 21/50\n",
      "2188/2188 - 19s - loss: 0.4943 - accuracy: 0.8190 - val_loss: 0.3466 - val_accuracy: 0.8755 - 19s/epoch - 9ms/step\n",
      "Epoch 22/50\n",
      "2188/2188 - 19s - loss: 0.4832 - accuracy: 0.8231 - val_loss: 0.3228 - val_accuracy: 0.8829 - 19s/epoch - 9ms/step\n",
      "Epoch 23/50\n",
      "2188/2188 - 19s - loss: 0.4704 - accuracy: 0.8271 - val_loss: 0.3174 - val_accuracy: 0.8840 - 19s/epoch - 9ms/step\n",
      "Epoch 24/50\n",
      "2188/2188 - 19s - loss: 0.4616 - accuracy: 0.8296 - val_loss: 0.3061 - val_accuracy: 0.8853 - 19s/epoch - 9ms/step\n",
      "Epoch 25/50\n",
      "2188/2188 - 19s - loss: 0.4481 - accuracy: 0.8349 - val_loss: 0.3059 - val_accuracy: 0.8882 - 19s/epoch - 9ms/step\n",
      "Epoch 26/50\n",
      "2188/2188 - 19s - loss: 0.4335 - accuracy: 0.8412 - val_loss: 0.3166 - val_accuracy: 0.8862 - 19s/epoch - 9ms/step\n",
      "Epoch 27/50\n",
      "2188/2188 - 19s - loss: 0.4251 - accuracy: 0.8439 - val_loss: 0.2680 - val_accuracy: 0.9030 - 19s/epoch - 9ms/step\n",
      "Epoch 28/50\n",
      "2188/2188 - 19s - loss: 0.4169 - accuracy: 0.8458 - val_loss: 0.2741 - val_accuracy: 0.9007 - 19s/epoch - 9ms/step\n",
      "Epoch 29/50\n",
      "2188/2188 - 19s - loss: 0.4040 - accuracy: 0.8523 - val_loss: 0.2592 - val_accuracy: 0.9069 - 19s/epoch - 9ms/step\n",
      "Epoch 30/50\n",
      "2188/2188 - 19s - loss: 0.3951 - accuracy: 0.8557 - val_loss: 0.2549 - val_accuracy: 0.9090 - 19s/epoch - 9ms/step\n",
      "Epoch 31/50\n",
      "2188/2188 - 19s - loss: 0.3901 - accuracy: 0.8575 - val_loss: 0.2544 - val_accuracy: 0.9087 - 19s/epoch - 9ms/step\n",
      "Epoch 32/50\n",
      "2188/2188 - 19s - loss: 0.3814 - accuracy: 0.8616 - val_loss: 0.2432 - val_accuracy: 0.9113 - 19s/epoch - 9ms/step\n",
      "Epoch 33/50\n",
      "2188/2188 - 19s - loss: 0.3741 - accuracy: 0.8622 - val_loss: 0.2342 - val_accuracy: 0.9176 - 19s/epoch - 9ms/step\n",
      "Epoch 34/50\n",
      "2188/2188 - 19s - loss: 0.3682 - accuracy: 0.8647 - val_loss: 0.2311 - val_accuracy: 0.9160 - 19s/epoch - 9ms/step\n",
      "Epoch 35/50\n",
      "2188/2188 - 19s - loss: 0.3632 - accuracy: 0.8669 - val_loss: 0.2433 - val_accuracy: 0.9136 - 19s/epoch - 9ms/step\n",
      "Epoch 36/50\n",
      "2188/2188 - 19s - loss: 0.3509 - accuracy: 0.8710 - val_loss: 0.2234 - val_accuracy: 0.9189 - 19s/epoch - 9ms/step\n",
      "Epoch 37/50\n",
      "2188/2188 - 19s - loss: 0.3411 - accuracy: 0.8744 - val_loss: 0.2122 - val_accuracy: 0.9262 - 19s/epoch - 9ms/step\n",
      "Epoch 38/50\n",
      "2188/2188 - 19s - loss: 0.3392 - accuracy: 0.8755 - val_loss: 0.2051 - val_accuracy: 0.9294 - 19s/epoch - 9ms/step\n",
      "Epoch 39/50\n",
      "2188/2188 - 19s - loss: 0.3316 - accuracy: 0.8780 - val_loss: 0.2040 - val_accuracy: 0.9274 - 19s/epoch - 9ms/step\n",
      "Epoch 40/50\n",
      "2188/2188 - 19s - loss: 0.3249 - accuracy: 0.8811 - val_loss: 0.1973 - val_accuracy: 0.9310 - 19s/epoch - 9ms/step\n",
      "Epoch 41/50\n",
      "2188/2188 - 19s - loss: 0.3234 - accuracy: 0.8813 - val_loss: 0.1972 - val_accuracy: 0.9314 - 19s/epoch - 9ms/step\n",
      "Epoch 42/50\n",
      "2188/2188 - 19s - loss: 0.3172 - accuracy: 0.8847 - val_loss: 0.2170 - val_accuracy: 0.9253 - 19s/epoch - 9ms/step\n",
      "Epoch 43/50\n"
     ]
    }
   ],
   "source": [
    "if (global_model_type == 'cnn'):\n",
    "    print('Start running cnn')\n",
    "    run_cnn_5_fold_cross_validation()\n",
    "elif (global_model_type == 'lstm'):\n",
    "    print('Start running lstm')\n",
    "    run_lstm_5_fold_cross_validation()\n",
    "elif (global_model_type == 'tune_cnn'):\n",
    "    print('Start tuning cnn')\n",
    "    tune_cnn()\n",
    "elif (global_model_type == 'tune_lstm'):\n",
    "    print('Start tuning lstm')\n",
    "    tune_lstm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
