{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import scipy\n",
    "import time\n",
    "import collections\n",
    "import itertools\n",
    "import librosa\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the directories of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'F:\\Aurora\\Documents/nsynth'\n",
    "\n",
    "#directory to training data and json file\n",
    "train_dir= base_path + '/nsynth-train/audio'\n",
    "\n",
    "#directory to training data and json file\n",
    "valid_dir= base_path + '/nsynth-valid/audio'\n",
    "# directory to training data and json file\n",
    "test_dir= base_path + '/nsynth-test/audio'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample files from each instrument family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw json files as given in the training set\n",
    "# The JSON files has information about the instrument family, instrument source, pitch, \n",
    "# velocity, and the audio file name \n",
    "df_train_raw = pd.read_json(path_or_buf= base_path + '/nsynth-train/examples.json', orient='index')\n",
    "df_train_raw = df_train_raw[df_train_raw.instrument_family != 9]\n",
    "\n",
    "#Sample n files from each instrument family\n",
    "n = 10\n",
    "df_train_sample = df_train_raw.groupby('instrument_family', as_index=False, #group by instrument family\n",
    "                               group_keys=False).apply(lambda df: df.sample(n)) #number of samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the sampled filenames for the train, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train = df_train_sample.index.tolist()\n",
    "\n",
    "# Tar ut alla filnamn från validation datasetet\n",
    "path = base_path + \"/nsynth-valid/examples.json\"\n",
    "df_valid = pd.read_json(path_or_buf=path, orient='index')\n",
    "\n",
    "filenames_valid = df_valid.index.tolist()\n",
    "\n",
    "\n",
    "# Tar ut alla filnamn från test datasetet\n",
    "path = base_path + '/nsynth-test/examples.json'\n",
    "df_test = pd.read_json(path_or_buf=path, orient='index')\n",
    "\n",
    "# save the train file index as list\n",
    "filenames_test = df_test.index.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for extracting data from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(file):\n",
    "    \"\"\"\n",
    "    Takes in a file name from the NSynth dataset and returns the melspectrogram of said file\n",
    "    Returns a 126x13 array\n",
    "    \"\"\"\n",
    "    \n",
    "    #get wave representation\n",
    "    y, sr = librosa.load(file, sr=16000)\n",
    "        \n",
    "    #Mel-frequency cepstral coefficients (MFCCs)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc = np.transpose(mfcc)\n",
    "    normalized_mfcc = (mfcc-np.min(mfcc))/(np.max(mfcc)-np.min(mfcc))\n",
    "\n",
    "    #get the mel-scaled spectrogram\n",
    "    #spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000) \n",
    "\n",
    "    #spectrogram = np.transpose(spectrogram)\n",
    "    #normalized_spectrogram = (spectrogram-np.min(spectrogram))/(np.max(spectrogram)-np.min(spectrogram))\n",
    "\n",
    "    return normalized_mfcc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_files(dir, filenames, pickle_file_name, break_after):\n",
    "    \"\"\"\n",
    "    Extracts data from all files specified in dir with a few exceptions\n",
    "\n",
    "    :param dir: The directory containing filenames\n",
    "    :param filenames: The list of filenames to run feature_extract on \n",
    "    :param pickle_file_name: The name of the file where the extracted data should be stored\n",
    "    :param break_after: Upper limit of the number of files to include in the pickle file.\n",
    "                        Used in order to speed up the process. Set this to -1 if you want\n",
    "                        to include all files in filenames.\n",
    "    \"\"\"\n",
    "    #create dictionary to store all test features\n",
    "    dict_test = {}\n",
    "    #loop over every file in the list\n",
    "    a = 0\n",
    "    for file in filenames:\n",
    "        # Break after a certain number of files.\n",
    "        # -1 means no break\n",
    "        if a == break_after:\n",
    "            break\n",
    "        a += 1\n",
    "        #extract the features\n",
    "        features = feature_extract(dir + '/' + file + '.wav') #specify directory and .wav\n",
    "        #add dictionary entry\n",
    "        features = features.tolist()\n",
    "        dict_test[file] = features\n",
    "    \n",
    "    #print(dict_test)\n",
    "    dict_data_frame = pd.DataFrame.from_dict(dict_test, orient=\"index\")\n",
    "\n",
    "    #save the dataframe to a pickle file\n",
    "    with open('CustomData/' + pickle_file_name, 'wb') as f:\n",
    "        pickle.dump(dict_test, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "prepare_files(train_dir, filenames_train, 'traindata1000.pkl', -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "prepare_files(test_dir, filenames_test, 'testdata100.pkl', 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the validation data\n",
    "prepare_files(valid_dir, filenames_valid, 'validdata100.pkl', 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c0d9e848de383e29e404c597115be9b45bc461045219b4d0178039bf23e19c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
